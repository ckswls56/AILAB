# ë‚´ë¶€ LLM API ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

## âœ… ì™„ë£Œëœ ë³€ê²½ì‚¬í•­

### 1. ìƒˆë¡œ ì¶”ê°€ëœ íŒŒì¼
- `llm_client.py`: ë‚´ë¶€ LLM API í´ë¼ì´ì–¸íŠ¸ (Ollama/vLLM í˜¸í™˜)

### 2. ìˆ˜ì •ëœ íŒŒì¼
- `qa_service.py`: OpenAI â†’ ë‚´ë¶€ LLM APIë¡œ ë³€ê²½
- `pdf_processor.py`: OpenAI Embeddings â†’ ë‚´ë¶€ ì„ë² ë”© APIë¡œ ë³€ê²½  
- `requirements.txt`: OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°, httpx ì¶”ê°€
- `env.example`: OpenAI ì„¤ì • ì œê±°, ë‚´ë¶€ LLM ì„¤ì • ì¶”ê°€

## ğŸ”§ ìƒˆë¡œìš´ í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
# ë‚´ë¶€ LLM API ì„¤ì • (ì±„íŒ… ì „ìš©)
LLM_API_URL=http://10.231.255.37:11434   # ë‚´ë¶€ LLM ì„œë²„ ì£¼ì†Œ
LLM_MODEL=gemma3:27b-it-q4_0             # ì‚¬ìš©í•  LLM ëª¨ë¸

# ë¡œì»¬ ì„ë² ë”© ëª¨ë¸ (CPUì—ì„œ ë™ì‘)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2   # sentence-transformers ëª¨ë¸
```

## ğŸš€ ë°°í¬ ì „ í™•ì¸ì‚¬í•­

### 1. ë‚´ë¶€ LLM ì„œë²„ ì¤€ë¹„
- Ollama ë˜ëŠ” vLLM ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì´ì–´ì•¼ í•¨
- `gemma3:27b-it-q4_0` ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆì–´ì•¼ í•¨
- âš ï¸ **ì„ë² ë”©ì€ ë¡œì»¬ CPUì—ì„œ ì²˜ë¦¬** (ë‚´ë¶€ ì„œë²„ ë¶ˆí•„ìš”)

### 2. API ì—”ë“œí¬ì¸íŠ¸ í™•ì¸
```bash
# LLM ì±„íŒ… í…ŒìŠ¤íŠ¸ (ì„ë² ë”©ì€ ë¡œì»¬ì—ì„œ ì²˜ë¦¬í•˜ë¯€ë¡œ í…ŒìŠ¤íŠ¸ ë¶ˆí•„ìš”)
curl -X POST http://10.231.255.37:11434/api/chat \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemma3:27b-it-q4_0",
    "messages": [{"role": "user", "content": "ì•ˆë…•í•˜ì„¸ìš”"}],
    "stream": false
  }'
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜
```bash
pip install httpx>=0.25.0 sentence-transformers>=2.2.0
```

## ğŸ”„ ê¸°ì¡´ OpenAI ì„¤ì • ì œê±°
- âŒ `OPENAI_API_KEY` í™˜ê²½ë³€ìˆ˜ ë¶ˆí•„ìš”
- âŒ `langchain-openai` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì œê±°ë¨
- âŒ OpenAI API ë¹„ìš© ë°œìƒí•˜ì§€ ì•ŠìŒ

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™” íŒ
- **ì±„íŒ…**: ë‚´ë¶€ LLM ì„œë²„ì—ì„œ ì²˜ë¦¬ (GPU ê¶Œì¥)
- **ì„ë² ë”©**: ë¡œì»¬ CPUì—ì„œ ì²˜ë¦¬ (GPU ë¶ˆí•„ìš”)
- ì„ë² ë”© ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥: `all-MiniLM-L6-v2` (ê¸°ë³¸), `all-mpnet-base-v2` (ê³ ì„±ëŠ¥)
- íƒ€ì„ì•„ì›ƒ ì„¤ì •: 120ì´ˆ (ì¡°ì • ê°€ëŠ¥)

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### LLM ì±„íŒ… ì˜¤ë¥˜ ì‹œ
1. LLM ì„œë²„ ìƒíƒœ í™•ì¸
2. `LLM_API_URL` ì„¤ì • í™•ì¸  
3. ë°©í™”ë²½/í¬íŠ¸ ì„¤ì • í™•ì¸

### ì„ë² ë”© ì˜¤ë¥˜ ì‹œ
1. `sentence-transformers` ì„¤ì¹˜ í™•ì¸
2. ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ìƒíƒœ í™•ì¸
3. ë©”ëª¨ë¦¬ ë¶€ì¡± ì—¬ë¶€ í™•ì¸ (CPU RAM)

### ì²« ì‹¤í–‰ ì‹œ ì„ë² ë”© ëª¨ë¸ ìë™ ë‹¤ìš´ë¡œë“œ
- `all-MiniLM-L6-v2` ëª¨ë¸ì´ ìë™ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë©ë‹ˆë‹¤ (~80MB)
- ì¸í„°ë„· ì—°ê²°ì´ í•„ìš”í•©ë‹ˆë‹¤

## ğŸ“‹ API ì—”ë“œí¬ì¸íŠ¸

### ğŸ“ íŒŒì¼ ì—…ë¡œë“œ

#### 1. ë‹¨ì¼ íŒŒì¼ ì—…ë¡œë“œ
```bash
POST /upload-pdf
Content-Type: multipart/form-data

# ì‘ë‹µ
{
  "success": true,
  "message": "PDF 'document.pdf' ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
  "document_id": "uuid-string",
  "chunks_count": 25
}
```

#### 2. ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ ğŸ†•
```bash
POST /upload-multiple-pdfs
Content-Type: multipart/form-data

# ì‘ë‹µ
{
  "total_files": 3,
  "successful_uploads": 2,
  "failed_uploads": 1,
  "processing_time": 45.2,
  "results": [
    {
      "filename": "doc1.pdf",
      "success": true,
      "message": "íŒŒì¼ 'doc1.pdf' ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
      "document_id": "uuid1",
      "chunks_count": 20,
      "error": null
    },
    {
      "filename": "doc2.pdf",
      "success": true,
      "message": "íŒŒì¼ 'doc2.pdf' ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
      "document_id": "uuid2", 
      "chunks_count": 15,
      "error": null
    },
    {
      "filename": "invalid.txt",
      "success": false,
      "message": "íŒŒì¼ 'invalid.txt': PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤.",
      "document_id": null,
      "chunks_count": null,
      "error": "PDF íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤."
    }
  ]
}
```

### ğŸ’¬ ì§ˆì˜ì‘ë‹µ
```bash
POST /ask
Content-Type: application/json

{
  "question": "ê³„ì•½ì„œì˜ ì£¼ìš” ì¡°ê±´ì€ ë¬´ì—‡ì¸ê°€ìš”?",
  "document_ids": ["uuid1", "uuid2"], // ì„ íƒì 
  "top_k": 5
}
```

### ğŸ“š ë¬¸ì„œ ê´€ë¦¬
```bash
GET /documents        # ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ
DELETE /documents/{id} # ë¬¸ì„œ ì‚­ì œ
```

## ğŸ³ Docker ì´ë¯¸ì§€ ìµœì í™”

### âš¡ **ìµœì í™”ëœ Dockerfile íŠ¹ì§•**

1. **Multi-stage Build**: ë¹Œë“œìš©/ëŸ°íƒ€ì„ìš© ë¶„ë¦¬
2. **CPU-only PyTorch**: GPU ë²„ì „ ëŒ€ë¹„ ~5GB ì ˆì•½
3. **ê²½ëŸ‰ ì„ë² ë”© ëª¨ë¸**: `paraphrase-MiniLM-L3-v2` (~50MB)
4. **ê°€ìƒí™˜ê²½ ì‚¬ìš©**: ê¹”ë”í•œ ì˜ì¡´ì„± ê´€ë¦¬
5. **ë³´ì•ˆ ê°•í™”**: non-root ì‚¬ìš©ì ì‹¤í–‰

### ğŸ“ **ì´ë¯¸ì§€ í¬ê¸° ë¹„êµ**

| ë²„ì „ | í¬ê¸° | ì„¤ëª… |
|------|------|------|
| âŒ **ê¸°ì¡´** | ~10GB | GPU PyTorch + í° ëª¨ë¸ |
| âœ… **ìµœì í™”** | ~1.5GB | CPU PyTorch + ê²½ëŸ‰ ëª¨ë¸ |

### ğŸš€ **ë¹Œë“œ ëª…ë ¹ì–´**

```bash
# ë°±ì—”ë“œ ë””ë ‰í† ë¦¬ì—ì„œ ë¹Œë“œ
cd project/backend
docker build -t pdf-qa-api:optimized .

# ì´ë¯¸ì§€ í¬ê¸° í™•ì¸
docker images pdf-qa-api:optimized
```

### ğŸ”§ **ì¶”ê°€ ìµœì í™” ì˜µì…˜**

#### 1. ë” ê°€ë²¼ìš´ ì„ë² ë”© ëª¨ë¸
```bash
# í™˜ê²½ë³€ìˆ˜ë¡œ ëª¨ë¸ ë³€ê²½ ê°€ëŠ¥
LOCAL_EMBEDDING_MODEL=paraphrase-MiniLM-L3-v2  # ~50MB (ê¸°ë³¸)
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2         # ~80MB (ë” ì •í™•)
LOCAL_EMBEDDING_MODEL=distiluse-base-multilingual-cased  # ë‹¤êµ­ì–´
```

#### 2. Alpine ê¸°ë°˜ (ë” ì‘ê²Œ)
```dockerfile
# ë” ì‘ì€ ì´ë¯¸ì§€ê°€ í•„ìš”í•˜ë©´ Alpine ì‚¬ìš©
FROM python:3.11-alpine
# ë‹¨, ì»´íŒŒì¼ ì‹œê°„ì´ ë” ì˜¤ë˜ ê±¸ë¦¼
```

### ğŸ› **ë¹Œë“œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…**

#### ìºì‹œ ë¬¸ì œ ì‹œ
```bash
docker build --no-cache -t pdf-qa-api:optimized .
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
```bash
# Docker Desktopì—ì„œ ë©”ëª¨ë¦¬ í• ë‹¹ëŸ‰ ì¦ê°€ (8GB ì´ìƒ ê¶Œì¥)
docker build --memory=8g -t pdf-qa-api:optimized .
```